# üöÄ Projet SENTHELP

SENTHELP est un projet de pipeline complet pour la **r√©colte, l‚Äôanalyse et la visualisation de tweets** en lien avec le secteur de l‚Äôassurance. Il se compose de trois grandes √©tapes :

1. Pipeline ETL avec Airflow  
2. Inf√©rence continue sur les nouveaux tweets  
3. Application Web pour visualiser les r√©sultats (backend FastAPI + frontend React)

---

## √âtape 1 : Pipeline ETL avec Airflow

Dossier : `SENTHELP/ETL-SENTHELP-main`

### Outils utilis√©s

- **Apache Airflow** : orchestration de la pipeline ETL (extraction, transformation, chargement).
- **MongoDB** : base de donn√©es NoSQL pour stocker les tweets nettoy√©s.
- **Grafana** et **Prometheus**: Pour le monitoring de la pipeline


### Fonctionnement de la pipeline

La pipeline ETL orchestr√©e par Airflow suit trois √©tapes principales :

1. **Extraction (Extract)** 
   - Cette t√¢che est orchestr√©e avec le `PythonOperator` dans Airflow.
   - Utilise la fonction extract_data/initialised_data pour extraire les tweets correspondant √† une p√©riode donn√©e.

2. **Transformation (Transform)**  
   - Utilisation √©galement du `PythonOperator`.
   - Utilise la fonction transform_data pour extraire les tweets correspondant √† une p√©riode donn√©e.

3. **Chargement (Load)**  
   - Orchestration avec le `PythonOperator`.
   - Utilise la fonction insert_mongo pour inserer des tweets dans une collection MongoDB.
   
---

### Fichiers importants

#### Dossier `dags/` ‚Äì Fichiers de d√©finition des workflows Airflow

| Fichier | Description |
|--------|-------------|
| `test_dag_X_0.py` | DAG d‚Äôinitialisation pour l‚Äôextraction compl√®te de l‚Äôhistorique (2006 √† juin 2026). |
| `test_dag_X_2.py` | DAG d‚Äôextraction quotidienne. |
| `test_dag_X_4.py` | DAG d‚Äôextraction hebdomadaire. |

> Chaque DAG est compos√© de trois t√¢ches principales, cr√©√©es √† partir des fonctions Python suivantes :

- **`initialize_data`** ou **`extract_data`**  
  - Ex√©cute le script `Nouvelalgo.py` en sous-processus.
  - Permet de r√©cup√©rer les tweets sur la p√©riode d√©finie.
  - Les tweets r√©cup√©r√©s sont sauvegard√©s dans un fichier `.json` temporaire.

- **`transform_data`**  
  - Charge les tweets extraits.
  - Applique un pr√©traitement √† chaque tweet.
  - Retourne une liste de tweets transform√©s (stock√©e dans XCom).

- **`insert_mongo`**  
  - R√©cup√®re les donn√©es nettoy√©es depuis `XCom`.
  - Convertit les formats de date et enrichit les m√©tadonn√©es.
  - Ins√®re les documents dans la base de donn√©es MongoDB.

#### Script Python d‚Äôextraction (`/scripts`)
- `Nouvelalgo.py` : 
Ce script est con√ßu pour √™tre ex√©cut√© en sous-processus et permet de r√©colter des tweets sur une p√©riode donn√©e, selon des mots-cl√©s d√©finis et une m√©thode de scraping s√©lectionn√©e.

---

### Fonctionnement g√©n√©ral

Le script fonctionne √† partir d'une s√©rie d'arguments fournis en ligne de commande. Il permet :

* De sp√©cifier une p√©riode de collecte (date et heure de d√©but et de fin),
* D'indiquer la m√©thode de scraping √† utiliser,
* De d√©finir un nombre de tweets √† r√©colter,
* Et d‚Äôopter pour une collecte continue jusqu‚Äô√† la fin de la p√©riode d√©finie.

---

### Arguments en entr√©e

* **`fichier`** : chemin vers un fichier JSON contenant les mots-cl√©s √† utiliser pour les recherches.
* **`heure`** et **`heurefin`** : heure de d√©but et de fin de la collecte (au format HH\:MM).
* **`datedebut`** et **`datefin`** : date de d√©but et de fin de la collecte (au format YYYY-MM-DD).
* **`methode`** : m√©thode de scraping choisie (`bs4`, `autoscraper`, etc.).
* **`nombre_tweets`** : nombre de tweets √† r√©cup√©rer (mettre `0` pour une collecte illimit√©e).
* **`--finrecolte`** *(optionnel)* : si activ√©, permet de continuer la collecte jusqu‚Äô√† la fin de la p√©riode sp√©cifi√©e.

---

### D√©roul√© du script

1. **Pr√©paration des param√®tres** :

   * Conversion des dates en timestamps.
   * Chargement des mots-cl√©s depuis le fichier JSON.

2. **Lancement de la collecte** :

   * La fonction `main()` est appel√©e avec les param√®tres fournis.
   * La collecte s'effectue via la fonction `recolte()` de mani√®re asynchrone.

3. **Sauvegardes** :

   * Les tweets collect√©s sont enregistr√©s dans un fichier `tweets_raw.json`.
   * Les m√©tadonn√©es de la requ√™te (par exemple, `req_id`) sont sauvegard√©es dans `req.json`.

---

### `recolte()`

* D√©clenche la m√©thode de scraping s√©lectionn√©e :

  * Utilise **Playwright** pour automatiser la navigation sur Twitter.
  * Si la m√©thode choisie est diff√©rente de `bs4`, les scrapers **AutoScraper** sont initialis√©s.
  * Utilise la fonction `login()` pour se connecter √† Twitter.

* Pour chaque dictionnaire de mots combin√©s dans le corpus :
  * G√©n√®re la combinaison des mots-cl√©s .
  * Affiche la page de recherche associ√© pour chaque combinaison.
  * Collecte les tweets √† l‚Äôaide de la m√©thode choisie (`scraping_bs4()` ou `scraping_autoscraper()`).
  * Met √† jour la liste des tweets r√©coltes, des identifiantes de tweets et les diff√©rents compteurs

* Conditions d'arr√™t de la collecte pour chaque mot-cl√© :

  1. La fin de la p√©riode d√©finie est atteinte.
  2. Le nombre de tweets souhait√© a √©t√© collect√© (si `--finrecolte` n‚Äôest pas activ√©).
  3. Plus aucun nouveau tweet n‚Äôest trouv√© malgr√© le scroll de la page.

* **D√©filement (scroll)** : effectu√© via `perform_scroll()` pour afficher de nouveaux tweets.

* En cas d‚Äô√©chec de la connexion √† Twitter :

  * Jusqu‚Äô√† **15 tentatives de reconnexion** sont effectu√©es.
  * Si l‚Äô√©chec persiste, la collecte est interrompue.

* Les sorties :
current_tweet_amount : nombre total de tweets r√©colt√©s jusqu‚Äô√† pr√©sent.
scroll_count : nombre de scrolls effectu√©s lors de la session.
termine : bool√©en indiquant si la collecte est termin√©e.
last_timestemp : timestamp du dernier tweet r√©colt√©, utile pour la continuit√© de la collecte.
lastdate : date du dernier tweet vu, au format lisible.
liste_tweets : liste des objets Tweet repr√©sentant les tweets collect√©s durant la session

---

### `login()`

Fonction d√©di√©e √† l‚Äôautomatisation de la connexion √† Twitter.

* Remplit automatiquement les champs d‚Äôidentifiant, d‚Äôe-mail (si n√©cessaire) et de mot de passe.
* Valide le formulaire de connexion.
* Retourne `True` si la connexion est r√©ussie, sinon `False`.

---

### `scraping_bs4()` et `scraping_autoscraper()`

Fonctions d‚Äôextraction des tweets pertinents selon les mots-cl√©s.

* Extraient le texte et l‚Äôidentifiant du tweet.
* V√©rifient la pr√©sence des mots-cl√©s dans le texte √† l‚Äôaide de la fonction `contient_mots_espaces()`.
* S‚Äôassurent que le tweet n‚Äôa pas encore √©t√© r√©colt√©.
* Extraient la date et v√©rifient qu‚Äôelle appartient bien √† la p√©riode de collecte.
* Si les conditions sont r√©unies, extraient les autres champs d‚Äôint√©r√™t (likes, etc.).
* Cr√©ent un objet `Tweet` √† partir des √©l√©ments r√©colt√©s ( avec la classe  `DonneeCollectee()` ).
* Rajoute l'objet √† la liste des tweets.
* Retourne :
  * Les compteurs mis √† jour (par mot-cl√©),
  * La liste des tweets r√©colt√©s,
  * La liste des identifiants des tweets associ√©s,
  * Le dernier timestamp et la derni√®re date vue, pour permettre la reprise de la collecte ult√©rieurement.

---

### `perform_scroll()`

Fonction de d√©filement de la page pour charger de nouveaux tweets.

* D√©tecte et clique sur un √©ventuel bouton **"Retry"** pour relancer le chargement.
* Compare les nouveaux √©l√©ments charg√©s avec les tweets d√©j√† r√©colt√©s.
* Retourne :

  * `True` si de nouveaux tweets ont √©t√© charg√©s,
  * `False` sinon, ce qui peut signaler une condition d‚Äôarr√™t de la collecte.

---

* Une fois la collecte termin√©e, le script retourne un bool√©en `finderecolte`qui signale si la r√©colte s'est bien effectu√©e.

---

### Fichiers g√©n√©r√©s

* `tweets_raw.json` : contient les tweets bruts collect√©s.
* `req.json` : contient les m√©tadonn√©es associ√©es √† la requ√™te.


## √âtape 2 : Inf√©rence Continue

Dossier : `SENTHELP/Inference-SENTHELP-main`

### Fonctionnement

- Utilisation des **MongoDB Change Streams** pour surveiller les nouvelles insertions de tweets dans la base.
- √Ä chaque nouvel enregistrement, une t√¢che d‚Äôinf√©rence (analyse de sentiment) est d√©clench√©e automatiquement.

### ‚ö†Ô∏è Pr√©requis
MongoDB doit √™tre configur√©e en **mode replica set** (obligatoire pour le fonctionnement des change streams).

---

## √âtape 3 : Application de Visualisation (Serving)

Dossier : `SENTHELP/Serving-SENTHELP-main`

###  Outils
- **Backend** : FastAPI : expose des endpoints pour interroger MongoDB.
- **Frontend** : ReactJS : permet une interface utilisateur interactive pour visualiser les r√©sultats.

---

### Backend (FastAPI)

Fichier principal :  
`Serving-SENTHELP-main/mongodb-with-fastapi/app.py`

- Fournit des routes API pour r√©cup√©rer les tweets
- Connect√© √† la base MongoDB.

---

### Frontend (React)

Dossier : `Serving-SENTHELP-main/frontend/src/components/`

| Composant | Fonction |
|----------|----------|
| `Cards.js` | Affiche les indicateurs statiques (score, pourcentage apr sentiments, etc.). |
| `Charts.js` | Composants graphiques pour les tendances. |
| `kpiFunctions.js` | Fonctions de calcul des KPI (Key Performance Indicators). |
| `Navbar.js` | Barre de navigation avec filtres temporels. |
| `Sidebar.js` | Menu lat√©ral pour naviguer dans l‚Äôapplication. |
| `Timeline.js` | S√©rie temporelle des tweets par date. |
| `toptweets.js` | Tableau des tweets les plus interactifs (likes, retweets, r√©ponses). |
| `wordcloud.js` | Nuage de mots bas√© sur les contenus des tweets. |

Autres fichiers importants :
- `App.js` : composant racine de l‚Äôapplication React.
- `App.css` : feuille de style globale.

---

## Lancement des composants

### 1. Lancement en une seule fois des trois services : 
Un script `start.sh` permet de d√©marrer automatiquement les trois services (ETL, inf√©rence, dashboard) en parall√®le :

```bash
start.sh
```
Ne pas oublier de mettre √† jour les chemins dans les fichiers : "start.sh" et "docker-compose.override.yml" 
### 2. Lancement manuel (dans trois terminaux s√©par√©s)

Vous pouvez aussi lancer chaque service **s√©par√©ment**, dans des terminaux diff√©rents :

#### Terminal 1 ‚Äî Pipeline ETL (Airflow via Astronomer)

```bash
cd /SENTHELP/ETL-SENTHELP-main
astro dev start
```

#### Terminal 2 ‚Äî Inf√©rence continue

```bash
cd /SENTHELP/Inference-SENTHELP-main
docker compose up
```

#### Terminal 3 ‚Äî Dashboard (FastAPI + React)

```bash
cd /SENTHELP/Serving-SENTHELP-main
docker compose up
```

---



